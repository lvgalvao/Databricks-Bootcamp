{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a214f77-1433-4eb1-8c06-687787ccdddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configurações de conexão com o banco PostgreSQL\n",
    "jdbc_url = \"jdbc:postgresql://dpg-cuciu352ng1s73b52bgg-a.ohio-postgres.render.com:5432/transactions_yz0m\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"transactions_yz0m_user\",\n",
    "    \"password\": \"66BsNmXaNh3btK1ZY8GLbnrFmwUFK9xY\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Nome da tabela no PostgreSQL\n",
    "postgres_table = \"transactions\"\n",
    "\n",
    "# Nome da tabela gerenciada no Databricks\n",
    "databricks_table = \"transactions\"\n",
    "\n",
    "# Carregar os dados do PostgreSQL para um DataFrame Spark\n",
    "transactions_df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", jdbc_url)\n",
    "    .option(\"dbtable\", postgres_table)\n",
    "    .option(\"user\", jdbc_properties[\"user\"])\n",
    "    .option(\"password\", jdbc_properties[\"password\"])\n",
    "    .option(\"driver\", jdbc_properties[\"driver\"])\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# Exibir amostra dos dados carregados\n",
    "transactions_df.show(5)\n",
    "\n",
    "# Salvar os dados diretamente em uma tabela gerenciada no Databricks\n",
    "transactions_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(databricks_table)\n",
    "\n",
    "print(f\"Tabela '{databricks_table}' criada com sucesso no Databricks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3675ad68-b225-40b2-80e5-351f4fd6967c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configurações de conexão com o banco PostgreSQL\n",
    "jdbc_url = \"jdbc:postgresql://dpg-cuciu352ng1s73b52bgg-a.ohio-postgres.render.com:5432/transactions_yz0m\"\n",
    "jdbc_properties = {\n",
    "    \"user\": \"transactions_yz0m_user\",\n",
    "    \"password\": \"66BsNmXaNh3btK1ZY8GLbnrFmwUFK9xY\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Nome da tabela no PostgreSQL e no Databricks\n",
    "postgres_table = \"transactions\"\n",
    "databricks_table = \"transactions\"\n",
    "\n",
    "# 1. Obter o último `transaction_time` da tabela gerenciada no Databricks\n",
    "last_transaction_time = spark.sql(f\"\"\"\n",
    "    SELECT MAX(transaction_time) AS last_transaction_time \n",
    "    FROM {databricks_table}\n",
    "\"\"\").collect()[0][\"last_transaction_time\"]\n",
    "\n",
    "# Verificar se há um `last_transaction_time` válido\n",
    "if last_transaction_time is None:\n",
    "    print(\"Nenhum dado encontrado na tabela gerenciada. Carregando todos os dados do PostgreSQL.\")\n",
    "    query = f\"(SELECT * FROM {postgres_table}) AS t\"\n",
    "else:\n",
    "    print(f\"Última transação encontrada: {last_transaction_time}. Carregando apenas os dados novos.\")\n",
    "    query = f\"\"\"\n",
    "        (SELECT * \n",
    "         FROM {postgres_table} \n",
    "         WHERE transaction_time > '{last_transaction_time}') AS t\n",
    "    \"\"\"\n",
    "\n",
    "# 2. Carregar apenas os dados novos do PostgreSQL para um DataFrame Spark\n",
    "new_transactions_df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", jdbc_url)\n",
    "    .option(\"dbtable\", query)\n",
    "    .option(\"user\", jdbc_properties[\"user\"])\n",
    "    .option(\"password\", jdbc_properties[\"password\"])\n",
    "    .option(\"driver\", jdbc_properties[\"driver\"])\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# Verificar se há dados novos para inserir\n",
    "if new_transactions_df.count() > 0:\n",
    "    print(f\"Inserindo {new_transactions_df.count()} novos registros na tabela gerenciada.\")\n",
    "    \n",
    "    # 3. Inserir os dados novos na tabela gerenciada\n",
    "    new_transactions_df.write.format(\"delta\").mode(\"append\").saveAsTable(databricks_table)\n",
    "    \n",
    "    print(\"Novos dados inseridos com sucesso!\")\n",
    "else:\n",
    "    print(\"Nenhum dado novo encontrado para inserção.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_postgres_transactions_create",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
