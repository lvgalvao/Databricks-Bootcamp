# Primeira aula

Nosso objetivo nessa primeira aula √© configurar nosso ambiente no Databricks, ter uma vis√£o da arquitetura geral do Spark (e do Databricks) e vamos ter um hands-on de c√≥digo.

## Configura√ß√£o Databricks

## Overview arquitetura Spark 

1. **B√°sico**  
   Introdu√ß√£o ao Apache Spark, seus conceitos fundamentais e aplica√ß√£o no gerenciamento de grandes volumes de dados.  

2. **Principais Componentes como Driver e Worker**  
   Explica√ß√£o sobre a arquitetura do Spark, incluindo os pap√©is do Driver (controle) e dos Workers (execu√ß√£o).  

Em um cluster Spark, o **executor** √© uma entidade crucial respons√°vel por realizar as tarefas (tasks) atribu√≠das a ele, processando dados e retornando resultados para o **driver**. Vamos analisar os conceitos relacionados aos executors e como eles funcionam no Databricks:

### **Executors no Spark**
1. **Tarefas e Execu√ß√£o**:
   - Os executors executam as **tasks**, que s√£o as unidades de trabalho paralelas no Spark.
   - Cada executor tem um conjunto de **slots**, que determinam quantas tasks ele pode executar simultaneamente (geralmente definido pelo n√∫mero de cores atribu√≠dos a ele).

2. **Mem√≥ria e Dados**:
   - Cada executor tem sua pr√≥pria mem√≥ria para armazenar dados em cache e executar opera√ß√µes.
   - A mem√≥ria de um executor √© compartilhada entre as tasks e armazenamentos intermedi√°rios (como o RDD ou dataframe em cache).

---

### **Executors no Databricks**
No Databricks, a configura√ß√£o padr√£o √© **1 executor por n√≥ de trabalho (worker node)**. Isso ocorre porque:
1. **Gerenciamento Simplificado**:
   - O Databricks otimiza os recursos alocando um executor por n√≥ de trabalho, reduzindo a complexidade do gerenciamento de mem√≥ria e comunica√ß√£o entre executors.

2. **Performance**:
   - O uso de 1 executor por n√≥ garante que todos os recursos do n√≥ (CPU, mem√≥ria) sejam dedicados a esse executor, maximizando a performance sem sobrecarga de competi√ß√£o entre m√∫ltiplos executors.

3. **Escalabilidade**:
   - Cada n√≥ pode ser ajustado verticalmente (com mais recursos) ou o cluster pode ser ajustado horizontalmente (com mais n√≥s).

4. **Cluster Gerenciado**:
   - No Databricks, o cluster √© gerenciado de forma a manter simplicidade e efici√™ncia, o que inclui essa decis√£o de design.

---

### **Compara√ß√£o: Spark Geral vs. Databricks**
| Caracter√≠stica             | Spark Geral                | Databricks                |
|----------------------------|----------------------------|---------------------------|
| Executors por Worker Node  | Pode ser m√∫ltiplos         | Sempre 1:1               |
| Gerenciamento de Recursos  | Configura√ß√£o manual        | Automatizado             |
| Mem√≥ria Compartilhada      | Entre m√∫ltiplos executors  | Inteiramente para 1 executor |

Essa arquitetura √© parte da estrat√©gia do Databricks para facilitar o uso e otimizar a performance de clusters gerenciados.

#### Slots

### Ponto Importante: Slots e N√∫cleos de CPU

Cada **executor** no Spark possui um n√∫mero de **slots** para executar as tasks simultaneamente, que est√° diretamente relacionado ao n√∫mero de **n√∫cleos de CPU** alocados para aquele executor.

#### Como Funciona:
1. **Slots e N√∫cleos**:
   - Um slot equivale a um n√∫cleo l√≥gico de CPU dispon√≠vel para executar uma task.
   - Por exemplo, se um executor tem 4 n√∫cleos de CPU alocados, ele ter√° 4 slots para executar at√© 4 tasks simultaneamente.

2. **Recursos no Worker Node**:
   - A quantidade de slots dispon√≠veis no executor deve ser dimensionada de acordo com os recursos totais do n√≥ de trabalho (worker node), garantindo que os n√∫cleos sejam suficientes para suportar as tasks sem causar sobrecarga ou competi√ß√£o excessiva.

3. **Databricks e Configura√ß√£o de Slots**:
   - No **Databricks**, como h√° um executor por n√≥ de trabalho, todos os n√∫cleos dispon√≠veis no n√≥ s√£o atribu√≠dos a esse √∫nico executor, garantindo que o n√∫mero de slots seja igual √† quantidade de n√∫cleos l√≥gicos dispon√≠veis.

---

### **Import√¢ncia dos Slots para Performance**
- **N√∫mero Suficiente de Slots**:
  - Um n√∫mero insuficiente de slots pode causar gargalos, com tasks esperando para serem processadas.
  - Um n√∫mero excessivo de slots (mais do que os n√∫cleos dispon√≠veis) pode levar a **overhead**, j√° que o sistema tenta dividir os recursos al√©m do limite ideal.

- **Ajuste Ideal**:
  - O n√∫mero de slots deve ser igual ou menor ao n√∫mero de n√∫cleos de CPU dispon√≠veis no n√≥ de trabalho.
  - No Databricks, isso j√° √© ajustado automaticamente, otimizando o uso dos recursos.

---

Essa configura√ß√£o alinhada entre slots e n√∫cleos garante efici√™ncia no processamento e maximiza o throughput em clusters Spark, especialmente em ambientes gerenciados como o Databricks.

### Pontos Relevantes sobre Executors e Execu√ß√£o no Spark

1. **Tasks e Slots**:
   - Um executor pode executar tantas **tasks** em paralelo quanto o n√∫mero de **slots** dispon√≠veis, que por sua vez √© determinado pelo n√∫mero de n√∫cleos de CPU alocados ao executor.
   - **Task**: √â a menor unidade de trabalho no Spark. Cada task processa um √∫nico **partition** de dados.

   **Exemplo**:
   - Se o cluster tiver **2 worker nodes**, cada um com **4 n√∫cleos de CPU**, o total ser√° de **8 slots**.
   - Isso significa que at√© **8 tasks** podem ser executadas simultaneamente no cluster.

2. **Parti√ß√µes e Tarefas**:
   - Os dados s√£o divididos em **partitions**, que formam a base para as tasks no Spark.
   - Cada partition √© processada por uma √∫nica task. Portanto, o n√∫mero de partitions define o n√∫mero m√≠nimo de tasks necess√°rias para processar os dados.

3. **Ambiente de Execu√ß√£o (JVM)**:
   - Tanto o **driver** quanto os **executors** s√£o processos que rodam na **JVM** (Java Virtual Machine).
   - O **driver** coordena a execu√ß√£o geral do aplicativo, enquanto os executors realizam o trabalho de processar as partitions e retornar os resultados.

---

### Exemplo Pr√°tico
- **Cen√°rio**:
  - Cluster com 2 workers, cada um com 4 n√∫cleos de CPU (8 slots no total).
  - Um dataset √© dividido em 16 partitions.

- **Execu√ß√£o**:
  - Inicialmente, 8 tasks ser√£o atribu√≠das para execu√ß√£o, uma para cada slot.
  - Assim que uma task √© conclu√≠da, o slot fica dispon√≠vel para processar outra partition at√© que todas as 16 tasks sejam completadas.

---

### Resumo
- **Tasks em Paralelo**: Limitadas pelo n√∫mero de slots no cluster.
- **Parti√ß√µes**: Devem ser configuradas adequadamente para equilibrar o trabalho entre os executors.
- **Execu√ß√£o na JVM**: Facilita a integra√ß√£o e interoperabilidade do Spark com v√°rias linguagens (como Python, Scala, e Java). 

Esse design escal√°vel e eficiente faz do Spark uma ferramenta poderosa para processar grandes volumes de dados.

3. **Spark UI**  
   Apresenta√ß√£o da interface Spark UI para monitorar e depurar jobs em execu√ß√£o.  

### M√©tricas spark UI

Esses dados s√£o m√©tricas de **performance** exibidas no **Spark UI**, que ajudam a entender como o trabalho do Spark foi executado. Vamos detalhar cada ponto para que voc√™ compreenda o que significam e como podem ser analisados:

---

### 1. **Task Deserialization Time**
- **O que √©?**: O tempo gasto para **deserializar** (interpretar) o c√≥digo da tarefa no executor.
- **Por que importa?**: Isso acontece no in√≠cio de cada tarefa. Se esse tempo for alto, pode indicar problemas com o tamanho ou complexidade dos objetos que est√£o sendo enviados para os executores.

---

### 2. **Duration**
- **O que √©?**: A dura√ß√£o total da tarefa, do in√≠cio ao fim.
- **Por que importa?**: √â a m√©trica mais √≥bvia para saber quanto tempo uma tarefa levou. Altos tempos podem indicar gargalos no processamento ou leitura de dados.

---

### 3. **GC Time (Garbage Collection Time)**
- **O que √©?**: O tempo gasto pelo **Garbage Collector (GC)** limpando mem√≥ria inutilizada.
- **Por que importa?**: Se o tempo de GC for alto, pode significar que sua aplica√ß√£o est√° consumindo muita mem√≥ria ou que os objetos n√£o est√£o sendo liberados eficientemente.

---

### 4. **Result Serialization Time**
- **O que √©?**: O tempo gasto para **serializar** (empacotar) o resultado da tarefa antes de envi√°-lo de volta ao driver.
- **Por que importa?**: Geralmente √© pequeno, mas valores altos podem indicar que os resultados da tarefa s√£o grandes ou complexos, dificultando a transmiss√£o.

---

### 5. **Getting Result Time**
- **O que √©?**: O tempo gasto para o driver receber os resultados da tarefa.
- **Por que importa?**: Geralmente √© insignificante. Se for alto, pode indicar lentid√£o na comunica√ß√£o entre o executor e o driver.

---

### 6. **Scheduler Delay**
- **O que √©?**: O tempo que a tarefa ficou esperando antes de ser executada.
- **Por que importa?**: Um alto **Scheduler Delay** pode significar:
  - N√£o h√° recursos suficientes no cluster (como CPU ou mem√≥ria).
  - O cluster est√° muito ocupado.
  - Problemas com a configura√ß√£o do paralelismo.

---

### 7. **Peak Execution Memory**
- **O que √©?**: A maior quantidade de mem√≥ria usada pela tarefa durante a execu√ß√£o.
- **Por que importa?**: Se for muito alta, pode haver falta de mem√≥ria no executor, levando a falhas ou ao uso de disco (swap).

---

### 8. **Input Size / Records**
- **O que √©?**: O tamanho e o n√∫mero de registros processados pela tarefa.
  - **Input Size**: O volume de dados que a tarefa leu (em MiB).
  - **Records**: Quantos registros foram lidos.
- **Por que importa?**: Permite entender a distribui√ß√£o do trabalho. Desequil√≠brios podem significar **skew** (dados mal distribu√≠dos).

---

### 9. **Shuffle Write Size / Records**
- **O que √©?**: O tamanho e o n√∫mero de registros escritos durante o **shuffle**.
  - **Shuffle Write Size**: O volume de dados escrito para o shuffle.
  - **Records**: Quantos registros foram enviados no shuffle.
- **Por que importa?**: Altos valores indicam que a tarefa est√° enviando muitos dados para outros executores, o que pode ser um gargalo.

---

### 10. **Shuffle Write Time**
- **O que √©?**: O tempo gasto para escrever dados no shuffle.
- **Por que importa?**: Um tempo alto pode indicar problemas de disco, rede, ou simplesmente que muitas tarefas est√£o tentando escrever ao mesmo tempo.

---

## Como usar essas m√©tricas?

### Identificando problemas comuns:
1. **Tasks demorando muito (Duration)**:
   - Verifique **GC Time**, **Scheduler Delay**, e **Input Size**.
   - Talvez precise aumentar os recursos ou otimizar a l√≥gica.

2. **Problemas de mem√≥ria (GC Time ou Peak Execution Memory)**:
   - Reduza o uso de objetos grandes ou ajuste configura√ß√µes como `spark.executor.memory`.

3. **Dados mal distribu√≠dos (Skew)**:
   - Verifique **Input Size / Records** e **Shuffle Write Size**. Se algumas tarefas t√™m dados muito maiores que outras, voc√™ pode precisar redistribu√≠-los.

Essas m√©tricas te ajudam a entender o comportamento do Spark e otimizar seus jobs para melhor desempenho! üöÄ

4. **Modos de Deploy (Deployment Modes)**  
   Diferentes formas de implementar o Spark: local, cluster e client-server.  

### Deployment Models no Apache Spark

O Apache Spark suporta v√°rios **modelos de deployment**, que determinam como o **driver**, os **executors** e os **worker nodes** interagem durante a execu√ß√£o de um job. Os principais modelos s√£o: **local**, **client**, e **cluster**.

---

### 1. **Local Deployment**
- **Descri√ß√£o**:
  - O Spark roda tudo (driver e executors) no **mesmo processo** ou na mesma m√°quina.
  - Ideal para desenvolvimento, teste ou processamento de pequenos volumes de dados.

- **Caracter√≠sticas**:
  - N√£o exige configura√ß√£o de cluster.
  - Simula a execu√ß√£o distribu√≠da em uma m√°quina local.
  - Geralmente usado no modo de desenvolvimento com o comando `local[N]`, onde **N** √© o n√∫mero de threads (ex.: `local[4]` usa 4 threads).

- **Vantagens**:
  - Simplicidade: N√£o h√° necessidade de gerenciar recursos distribu√≠dos.
  - Ideal para testes r√°pidos e debugging.

- **Limita√ß√µes**:
  - N√£o escal√°vel para grandes volumes de dados.
  - Limitado pelos recursos da m√°quina local.

---

### 2. **Client Deployment**
- **Descri√ß√£o**:
  - O **driver** roda na m√°quina do cliente (a partir do qual o job √© enviado), enquanto os **executors** rodam nos **worker nodes** do cluster.
  - O cliente mant√©m a comunica√ß√£o direta com os executors.

- **Caracter√≠sticas**:
  - O driver precisa estar ativo durante toda a execu√ß√£o do job.
  - Usado geralmente para interatividade, como no Spark Shell ou notebooks.

- **Vantagens**:
  - Simples de configurar em um cluster existente.
  - Permite controle direto do job a partir do cliente.

- **Limita√ß√µes**:
  - Dependente da m√°quina do cliente: se ela falhar, o job ser√° interrompido.
  - Lat√™ncia maior se o cliente estiver distante do cluster (por exemplo, em diferentes regi√µes).

---

### 3. **Cluster Deployment**
- **Descri√ß√£o**:
  - Tanto o **driver** quanto os **executors** rodam no cluster. O job √© enviado ao cluster e gerenciado completamente por ele.
  - Modelos comuns de clusters incluem **YARN**, **Kubernetes**, e **Standalone**.

- **Caracter√≠sticas**:
  - O cluster gerencia toda a execu√ß√£o do job, independentemente do cliente.
  - O cliente envia o job, mas n√£o precisa permanecer ativo.

- **Vantagens**:
  - Escalabilidade: Projetado para grandes volumes de dados.
  - Resili√™ncia: Menos depend√™ncia do cliente, maior toler√¢ncia a falhas.
  - Flexibilidade: Suporte a v√°rios gerenciadores de cluster.

- **Limita√ß√µes**:
  - Configura√ß√£o mais complexa em compara√ß√£o com o modelo local ou client.
  - Pode exigir recursos adicionais para gerenciar o cluster.

---

### Compara√ß√£o dos Modelos

| Caracter√≠stica       | **Local**          | **Client**           | **Cluster**        |
|----------------------|--------------------|----------------------|--------------------|
| **Driver**           | Local              | Na m√°quina do cliente| No cluster         |
| **Executors**        | Local              | No cluster           | No cluster         |
| **Escalabilidade**   | Baixa              | M√©dia                | Alta               |
| **Uso Comum**        | Testes/Desenvolvimento | Jobs interativos     | Processamento em larga escala |
| **Resili√™ncia**      | N/A                | Baixa (dependente do cliente) | Alta               |

---

Esses modelos oferecem flexibilidade ao Spark para atender a diferentes casos de uso, desde desenvolvimento local at√© processamento de grandes volumes de dados em clusters distribu√≠dos. A escolha do modelo depende da escala, interatividade e requisitos do projeto.


5. **RDDs, DataFrames e Datasets**  
   Compara√ß√£o entre as principais abstra√ß√µes de dados no Spark e suas aplica√ß√µes pr√°ticas.  

### Compara√ß√£o entre RDD, DataFrame e Dataset no Apache Spark

O Apache Spark fornece tr√™s APIs principais para processar dados: **RDD**, **DataFrame** e **Dataset**. Cada uma delas tem suas caracter√≠sticas, vantagens e desvantagens, dependendo do caso de uso.

---

### **1. Resilient Distributed Dataset (RDD)**
- **Descri√ß√£o**:
  - √â a API mais b√°sica e de baixo n√≠vel do Spark.
  - Representa uma cole√ß√£o imut√°vel de objetos distribu√≠dos por um cluster.

- **Caracter√≠sticas**:
  - **Imut√°vel**: N√£o pode ser alterado ap√≥s a cria√ß√£o.
  - **Distribu√≠do**: Dividido em v√°rias parti√ß√µes que s√£o processadas paralelamente.
  - **Sem Esquema**: Trabalha diretamente com objetos ou cole√ß√µes de dados, sem informa√ß√µes de tipo ou esquema.
  - **Lazy Evaluation**: Opera√ß√µes n√£o s√£o executadas imediatamente, mas apenas quando uma a√ß√£o (como `collect()`) √© chamada.

- **Vantagens**:
  - Flexibilidade para manipular qualquer tipo de dado.
  - Controle granular sobre o processamento de dados.

- **Desvantagens**:
  - Menos otimizado: N√£o aproveita as otimiza√ß√µes do Catalyst e Tungsten.
  - Requer mais c√≥digo para tarefas comuns (como filtragem e agrupamento).

---

### **2. DataFrame**
- **Descri√ß√£o**:
  - API de alto n√≠vel baseada em **esquema** que representa dados em um formato tabular (semelhante a uma tabela SQL ou um dataframe do pandas).
  - Implementado sobre RDD, mas com muitas otimiza√ß√µes internas.

- **Caracter√≠sticas**:
  - **Esquema**: Colunas nomeadas e tipos de dados definidos.
  - **Otimiza√ß√µes**: Usa o Catalyst Optimizer para otimizar consultas.
  - **Abstra√ß√£o**: Fornece uma interface declarativa semelhante ao SQL.

- **Vantagens**:
  - F√°cil de usar com opera√ß√µes SQL-like.
  - Melhor desempenho devido a otimiza√ß√µes internas.
  - Suporte a v√°rias fontes de dados (CSV, Parquet, JSON, etc.).

- **Desvantagens**:
  - N√£o √© t√£o flex√≠vel quanto RDD para manipula√ß√£o de tipos de dados personalizados.
  - Fracamente tipado (em compara√ß√£o com Dataset).

---

### **3. Dataset**
- **Descri√ß√£o**:
  - API que combina os benef√≠cios do RDD e DataFrame.
  - Oferece um **esquema** como o DataFrame, mas √© **fortemente tipado**, permitindo maior controle e seguran√ßa em tempo de compila√ß√£o.

- **Caracter√≠sticas**:
  - **Fortemente Tipado**: Usa classes case no Scala e tipos no Java.
  - **Esquema**: Define colunas e tipos como o DataFrame.
  - **Opera√ß√µes de Alto N√≠vel**: Semelhante ao SQL e DataFrame.
  - **Compatibilidade**: Pode ser convertido facilmente entre RDD e DataFrame.

- **Vantagens**:
  - Mais seguro e f√°cil de depurar devido ao suporte a tipos.
  - Otimiza√ß√µes autom√°ticas via Catalyst Optimizer.
  - Combina a expressividade do RDD com a efici√™ncia do DataFrame.

- **Desvantagens**:
  - Pode ser mais verboso do que DataFrame.
  - Dispon√≠vel apenas em Scala e Java (n√£o em Python).

---

### **Compara√ß√£o Direta**

| Aspecto               | **RDD**                       | **DataFrame**                 | **Dataset**                   |
|-----------------------|-------------------------------|-------------------------------|-------------------------------|
| **Tipo**              | Sem esquema                  | Esquema fraco                | Esquema forte (tipado)        |
| **Otimiza√ß√µes**       | Sem otimiza√ß√µes              | Catalyst Optimizer            | Catalyst Optimizer            |
| **Performance**       | Mais lento                   | Mais r√°pido                   | Mais r√°pido                   |
| **Verifica√ß√£o de Tipo** | Em tempo de execu√ß√£o         | Em tempo de execu√ß√£o          | Em tempo de compila√ß√£o        |
| **Facilidade de Uso** | Complexo                     | F√°cil com SQL-like API        | M√©dio                         |
| **Flexibilidade**     | Alta                         | M√©dia                         | Alta                          |
| **Suporte a Linguagens** | Scala, Java, Python          | Scala, Java, Python, R        | Scala, Java                   |

---

### **Quando Usar Cada API**

1. **RDD**:
   - Quando voc√™ precisa de controle total sobre o processamento de dados.
   - Para manipular tipos de dados personalizados.
   - Quando voc√™ est√° migrando aplicativos antigos baseados em RDD.

2. **DataFrame**:
   - Para processamento de dados estruturados/tabulares.
   - Quando o desempenho √© cr√≠tico e voc√™ quer aproveitar as otimiza√ß√µes autom√°ticas.
   - Para an√°lises SQL-like ou integra√ß√£o com ferramentas de BI.

3. **Dataset**:
   - Quando voc√™ precisa de verifica√ß√µes de tipo em tempo de compila√ß√£o.
   - Para pipelines de ETL que requerem transforma√ß√µes complexas com seguran√ßa de tipo.
   - Quando voc√™ quer combinar a facilidade do DataFrame com a flexibilidade do RDD.

---

### Conclus√£o

Escolha **RDD** para flexibilidade bruta, **DataFrame** para simplicidade e performance, e **Dataset** para seguran√ßa de tipo e expressividade. Cada API tem seus casos de uso, e a escolha depende do seu cen√°rio espec√≠fico.


6. **Transforma√ß√µes e A√ß√µes (Transformations and Actions)**  
   Explica√ß√£o sobre opera√ß√µes no Spark, distinguindo entre aquelas que preparam o pipeline (transforma√ß√µes) e as que executam os c√°lculos (a√ß√µes).  

Em sistemas de processamento de dados como o Spark, **Transforma√ß√µes** e **A√ß√µes** s√£o os dois tipos principais de opera√ß√µes realizadas em conjuntos de dados. Apesar de ambos serem opera√ß√µes, eles t√™m finalidades e comportamentos distintos:

---

### **Transforma√ß√µes**
- **O que s√£o?** Opera√ß√µes que criam um novo conjunto de dados a partir de um existente, sem executar imediatamente o processamento.
- **Caracter√≠sticas principais:**
  - S√£o **lazy** (pregui√ßosas), ou seja, n√£o executam imediatamente. Apenas descrevem como os dados devem ser transformados.
  - Retornam um novo **RDD** (ou DataFrame/Dataset) representando a transforma√ß√£o aplicada.
  - Exemplos: `map()`, `filter()`, `groupByKey()`, `reduceByKey()`, `select()`, etc.
  - S√£o **encade√°veis**: voc√™ pode aplicar v√°rias transforma√ß√µes em sequ√™ncia antes de executar o processamento.

#### **Exemplo:**
```python
# Aplicando uma transforma√ß√£o (lazy)
dados_filtrados = dados.filter(lambda x: x['idade'] > 18)
```
Nesse momento, nenhum dado foi processado. Apenas foi criada a defini√ß√£o do que deve ser feito.

---

### **A√ß√µes**
- **O que s√£o?** Opera√ß√µes que iniciam o processamento e retornam um resultado ou salvam os dados em algum local.
- **Caracter√≠sticas principais:**
  - S√£o **eager** (executadas imediatamente). Ao serem chamadas, disparam o pipeline de transforma√ß√µes descrito anteriormente.
  - Retornam um **valor** ou **escrevem dados** em um destino (como arquivos ou bancos de dados).
  - Exemplos: `count()`, `collect()`, `take(n)`, `saveAsTextFile()`, `show()`, etc.

#### **Exemplo:**
```python
# Executando uma a√ß√£o (eager)
resultado = dados_filtrados.collect()
print(resultado)
```
Aqui, o processamento √© realizado, aplicando o filtro definido anteriormente, e os dados resultantes s√£o coletados.

---

### **Resumo das diferen√ßas:**

| Aspecto               | Transforma√ß√µes                          | A√ß√µes                              |
|-----------------------|------------------------------------------|------------------------------------|
| **Execu√ß√£o**          | Lazy (n√£o executa imediatamente)        | Eager (executa imediatamente)     |
| **Objetivo**          | Criar um novo conjunto de dados         | Retornar resultados ou salvar dados |
| **Retorno**           | Novo RDD/DataFrame                     | Valor ou escrita no armazenamento |
| **Exemplos**          | `map`, `filter`, `select`, `groupByKey` | `count`, `collect`, `show`, `saveAsTextFile` |

---

Ambos trabalham em conjunto: **as transforma√ß√µes definem o que ser√° feito, e as a√ß√µes disparam o processamento necess√°rio para gerar os resultados.**


7. **Jobs, Stages e Tasks**  
   Estrutura de execu√ß√£o do Spark: como um job √© dividido em est√°gios e tarefas para otimizar o processamento.  


## API e hands-on Spark